\renewcommand*{\afterpartskip}{
\vfil
\begin{epigraphs}
\qitem{\itshape
“Jo, hvis dét skal kaldes Fakta, saa benægter a Fakta!”
}{folketingsmedlem Søren Kjær, i debat med Carl Steen Andersen Bille}
\qitem{\itshape
  Politik skal ikke videnskabeliggøres. Der findes ikke noget facit i politik – kun følelser og holdninger. Begreber som sandt og falsk eller godt og ondt har ganske enkelt ikke hjemme i det politiske rum. 
}{Peter Skaarup, i et ugebrev for Dansk Folkeparti, \citeyear{skaarupPolitikErForst2017}}
\end{epigraphs}}

\part{Analyse}\label{part:analysis}

\chapter{At beskrive den sociale virkelighed}


Denne opgave tager udgangspunkt i, at der antages at være en intersubjektiv social virkelighed, og det er muligt at undersøge denne.
Jeg læner mig videre op af et socialkonstruktionistisk verdensbillede; hvor denne sociale verden er i kontinuerlig tilblivelse i en kollektiv samskabelsesproces \todo{kilde socialkonstruktionisme}.
Ikke dermed sagt, at der altid er enighed omkring konturene af denne samskabte sociale virkelighed — heller ikke i politik.
Dette understreges, måske lidt kækt, af Søren Kjær på titelbladet for denne del af specialet\todo{kontekst - man skal argumentere for sine udtalelser; og underbygge sine argumenter}.
Der er et spil der skal spilles; og præmien er en vis form for  “trappen” fra del III; og undervejs belyse mine undersøgelsesspørgsmål efterhånden som der dukker noget op; så at sige.
Jeg vil også illustrere de særegenheder jeg måtte finde i mit datasæt undervejs; 

\chapter{Indskrænkning af dokumenter til undersøgelse}

Jeg begynder med, at udarbejde et tf-idf objekt for hver analyseperiode.
En analyseperiode udgør således et korpus, hvor teksten er blevet forhåndsbehandlet og klargjort.
For at øge analyseværdien har jeg udeladt ord der falder under gennemsnitsværdien for \textit{tf-idf} for dermed at sortere de aller mes hyppigt forekommende ord fra.
For at undgå, at de aller mest sjældne ord forvrænger analysen, udelukker jeg herefter ord der har en \textit{tf-idf} i de yderste to promille.

Derefter foretager jeg en sammenligning af forskellige modeller for beregning af det optimale emner for videre analyse.

\begin{figure}
\input{../fig/models_edu_test_5to125by10.tex}
\caption{Beregning af optimalt antal emner for videre analyse; bigrams og ingen stopord.}
\label{fig:modelsFull}
\end{figure}

Figur ~\ref{fig:modelsFull} (side ~\pageref{fig:modelsFull}) viser en sammenligning af 4 forskellige modeller for udvælgelse af et "optimalt" antal emner for en LDA-baseret topic model.
Ved at se på kurvene fra disse sammenligninger, konvergerer kurvene omkring de 30-50 emner, inden de bevæger sig opad igen\footnote{Med undtagelse af \autocite{deveaudAccurateEffectiveLatent2014}; der ikke ser ud til at være en særlig hjælpsom algoritme i denne sammenhæng. Muligvis en konsekvens af mit noget specielle datasæt.}.
Jeg går videre med 45 emner, da det er her; der er størst enighed for hver kurve.

En LDA beregning giver ikke navngivne emner, som sådan.
I kraft af at være en ikke-superviseret algoritme, bliver dokumenterne fordelt ud over det anviste antal emner\footnote{LDA tildeler dokumenterne en score $\gamma$ mellem 0 og 1 for deres bidrag til et givet emne. Emner er distributioner over begreber; hvor hvert begreb tildeles en score $\beta$ mellem 0 og 1 for at tilhøre et givet emne. \\ \\ Hvert emne $\phi k$ er en multinominel distribution over ordforrådet $W$, og hvert dokument $\theta  d$er en multinominel distribution over $K$ emner. Dermed er sandsynligheden for at et givet dokument ($d$) bidrager til emnet $k$ $\theta _{d,k}$; og sandsynligheden for at ord $w$ tilhører et emne $\phi _{k,w}$. De multinominale distributioner for emnet genereres af en konjugat Dirichlet prior((FIXME: dansk begreb?)) $\overrightarrow{\beta}$, og distributionerne for dokumenter på baggrund af en Dirchlet prior $\overrightarrow{\alpha}$. Deraf navnet \textit{“Latent Dirichlet Allocation”} \autocite[s.65f]{deveaudAccurateEffectiveLatent2014}} , i det omfang (algoritmen mener) de ligner hinanden.
Hvorvidt der er grupperinger der giver mening for mennesker i en social kontekst, og hvilken mening de eventuelt skulle have, er op til forskeren at vurdere.
Som eksempel præsenteres emnerne genereret for perioden 1990 til 2000; repræsenteret af de 15 hyppigste termer pr emne, rangeret efter prævalens.

\begin{figure}
\begin{adjustwidth}{-1in}{-1in}
  \input{../fig/terms_edu_test.tex}
\end{adjustwidth}
\caption{Oversigt over udvalgte emner for perioden 1990-2000, med tilhørende begreber.}
\label{fig:termsFull}
\end{figure}

Et overblik over de genererede emner (Figur ~\ref{fig:termsFull}, side ~\pageref{fig:termsFull}) viser, at der er del “støj” i form af administrivia, formalia og 'jeg synes' og så videre.
Der er dog nogle emner der har (pædagogisk) sociologisk relevans.

Man kan se der var tale om Tamil-sagen, i emne ??; og man kan se ??? i emne ???.
Men mest interessant for mit vedkommende er emne ???; der er repræsenteret af termerne “ung menneske”, "videregående uddannelse”, “i praktik”, blandt andre.

For at se om jeg kan øge informationstætheden forsøger jeg en ny runde; denne gang med en række generelle \autocite{stopwords-isoStopwordsISO2020} plus nogle domænespecifikke stopord\footnote{for den konkrete stopordsliste se \texttt{lib/stopwords.txt} i specialets Gitub-repositorie.}.

\begin{figure}
\input{../fig/models_edu_test_5to125by10.tex}
\caption{Differentiering mellem emner for forskellige antal emner; bigrams og stopord.}
\label{fig:models_stopwords}
\end{figure}

Dette viser sig dog at være en blindgyde, som vist i figur ~\ref{fig:modelsStopwords}.
Kurverne er nu uden det pæne “buk”\footnote{Igen, på nær \autocite{deveaudAccurateEffectiveLatent2014}}, og svinder ned mod 0; uden der er en opadstigende kurve.
Et uddrag af begreber, med antal emner sat til 45, giver tilsvarende utilfredsstillende resultater.
At sortere stopordene fra har tilsyneladende medført for stort informationstab til at der er analyseværdi tilbage.
Muligvis ville det være muligt at tilpasse listen af stopord; men dette er blevet udeladt af tidshensyn\footnote{Det tager flere dage til over en uge at sammenligne modellerne}.

\section{Talernes indbyrdes relationer}
Som tidligere nævnt har hvert datasæt sine særegenheder.
Jeg formodede i mit metodeafsnit, at der var en forholdsvis stor ensartethed i min samling af taler.
Min hypotese er, at dette skyldes den noget kunstfærdige situation en folketingstale befinder sig i.
Talernes kontekst, lejret i det politiske spil, bringer en række rammer for talerne; der i sidste ende formodentlig får en tale til at ligne mange andre.
Dette er illustreret ved figur ~\ref{fig:dendro_all}; hvor emnernes indbyrdes relationer for alle perioder fremgår\footnote{Graferne for de andre perioder kan ses på \href{martinandreasandersen.com/projects/au/}{min blog}}.
Disse begreber (og de tilhørende dokumenter) vil dog ikke være de samme som begreberne for de individuelle perioder lagt sammen; da modellen laver beregningen på bagrund af alle dokumenter på en gang.
For at bringe denne diskussion tilbage til en sociologisk relevans, kan også visualisere hvilke emner, computeren mener er nært beslægtede med emnerne omkring uddannelse.

\begin{figure}
  \input{../fig/cluster_edu_test.tex}
  \caption{LDA-modellens emner for perioden 2014-20, efter indbyrdes relationer. Emner repræsenteres med deres mest fremtrædende begreb.}
\label{fig:dendro_all}
\end{figure}

Ved udtræk af modellen for ??? emner, får jeg emner repræsenteret af følgende termer:

\chapter{Analyse af de udvalgte dokumenter}

Jeg har nu en samling dokumenter, der ser ud til, at kunne omhandle uddannelse.
Disse trækkes ud til videre analyse.
Først vil jeg se, hvilke termer der er gennemgående i dokumenterne, med en ordoptælling.
Derefter vil jeg undersøge, hvorvidt der er emner at trække ud indenfor disse dokumenter.
Jeg vil derefter køre en analyse, der har til sigte at afdække partipolitiske positioner over dette subset.

\section{Gennemgående termer for hver periode}

\begin{figure}
  \caption{De 20 mest omtalte termer for de udvalgte dokumenter, fordelt over de definerede analyseperioder.} 
\end{figure}

\subsection{Hvilke begreber er kendetegnende for de politiske fløje}
\todo{hvordan dele op i fløje}

\section{Emner indenfor uddannelse}

\section{Partipolitiske positioner}

Ordoptellingen ovenfor er en noget simplistisk tilgang til at afdække partipolitiske positioner.
Der er udarbejdet konkrete algoritmer for at undersøge dette.
Jeg vil benytte mig af den før omtalte \texttt{wordfish}-algoritme \autocite{slapinScalingModelEstimating2008}.

